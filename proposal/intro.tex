\chapter{Introduction}{}
\label{sec:intro}

% \lettrine[lraise=0.1, nindent=0em, slope=-.5em]{T}{HE RECENT RISE} of Internet-scale code search engines---e.g., Seahawk~\cite{Bacchelli:2012dl}, Portfolio~\cite{McMillan:2011wq}, Sourcerer~\cite{Bajracharya:2006vn}, Koders~\footnote{\url{http://www.koders.com}}---has catapulted search-driven development from backwater to ubiquity, and given rise to an active research community focused on this phenomena~\cite{Bajracharya:2009fj, Bajracharya:2010iy, Bajracharya:2011kw}. The increased prevalence of such engines has given search-driven development more diverse sources of information---e.g., from open sourced code to code snippets from StackOverflow~\footnote{\url{http://www.stackoverflow.com}}---and a more open platform---the Internet~\cite{GallardoValencia:2009gr, GallardoValencia:2010ij, Ying:2012tr}. This new condition has enabled developers to build applications opportunistically by iteratively finding, combining, and reusing online source code~\cite{Brandt:2008wi, Brandt:2009jb, Ying:2012tr}. This opportunistic way of building applications is not easy because searched sources are large, in most cases unsuitable, and quite often unrelated~\cite{GallardoValencia:2009gr}. Consequently, if search-driven development were to be established as best practice, then the time involved in deciding the best search result(s) to reuse must be minimized.

\lettrine[lraise=0.1, nindent=0em, slope=-.5em]{T}{HE RECENT RISE} of Internet-scale code search engines---e.g., Seahawk~\cite{Bacchelli:2012dl}, Portfolio~\cite{McMillan:2011wq}, Sourcerer~\cite{Bajracharya:2006vn}, Koders~\footnote{\url{http://www.koders.com}}---has catapulted search-driven development from backwater to ubiquity, and given rise to an active research community focused on this phenomena~\cite{Bajracharya:2009fj, Bajracharya:2010iy, Bajracharya:2011kw}. The increased prevalence of such engines has given search-driven development more diverse sources of information---e.g., from open sourced code to code snippets from StackOverflow~\footnote{\url{http://www.stackoverflow.com}}---and a more open platform---the Internet. This new condition has enabled developers to build applications opportunistically by iteratively finding, combining, and reusing online source code~\cite{Brandt:2008wi, Ncube:2008fm, Brandt:2009jb, McMillan:2012dj}. This opportunistic way of building applications is not easy because searched sources are large, in most cases unsuitable, and quite often unrelated~\cite{GallardoValencia:2009gr}. Consequently, if search-driven development were to be established as best practice, then the time involved in deciding the best search result(s) to reuse must be minimized.

Obviously, code search all by itself won't solve the whole problem. In fact, code-only searching misses out on certain human abilities that are important in search-driven development, such as the ability to quickly identify---based on knowledge and experience---better results among a myriad of retrieved examples, to demarcate feasible regions of code, and to transform results into code that resembles what existed only in the human mind. Previously published work has started tackling these issues from different directions\footnote{Two of these directions are the most popular: enhancing search technology~\cite{Bajracharya:2010um, Gysin:2010kt, McMillan:2011cm, McMillan:2012dj, Ying:2012tr}, and coupling Web search and crowdsourced input with IDEs~\cite{Bacchelli:2012dl, Brandt:2010tp, Hartmann:2010hx, Hoffmann:2007wo, Oney:2012ge, Wightman:2012gc}}; each with unique strengths and weaknesses. However, tool support for predetermining the suitability of any search result based on the above abilities is inchoate: developers are given no guidance as to which result may be a best fit for their code in progress, beyond the existing ranking values. In fact, developers still have to \emph{manually} mine and try all these results before they could possibly realize the results' usefulness---or uselessness. This limitation is one of the reasons why search-driven development is so cumbersome, and ultimately can be a drain on one of the most precious resources in software development: time.


% Previously published work has tried to tackle the above problem from different directions. Two of these directions are the most popular. One direction focuses entirely on enhancing search technology~\cite{Bajracharya:2010um, Gysin:2010kt, Mandelin:2005uj, McMillan:2011cm, McMillan:2012dj}, while the other direction focuses on coupling Web search and crowdsourced input with IDEs~\cite{Bacchelli:2012dl, Brandt:2010tp, Hartmann:2010hx, Hoffmann:2007wo, Wightman:2012gc}. Although these directions focus on addressing the trustability and relevance of search results, none of them adequately address the \emph{suitability} of these results. In other words, developers are given no guidance as to which result may be a best fit for their code in progress, beyond the existing ranking values. Precisely, developers still have to \emph{manually} mine and try all these ranked results before they could possibly realize their usefulness---or uselessness. This limitation is one of the reasons why search-driven development is so cumbersome, and ultimately can be a drain on one of the most precious resources in software development: time.


An increasingly familiar example of search-driven development arises when modifying a program to support a particular set of functionality. Sometimes, the task is to reuse external third-party libraries, or to support algorithms with specific performance characteristics. Other times, a developer may want to support a feature implemented by code with a conflicting API\footnote{Application Programming Interface (API)}. A good example would be adapting a sentiment analysis tool (that uses the Twitter API) to use the Facebook API. This type of tool permits the classification of opinions in text (e.g., status updates in Twitter) into categories like ``positive'' or ``negative.'' 

The increased prevalence of open source software and code search tools makes it simpler to find large sets of relevant examples. For example, one could find around fifty platform-specific Facebook libraries and a few dozen general-purpose Facebook libraries on Github\footnote{\url{http://www.github.com}}, each with differences and similarities. Tool support for determining if any source code found in those libraries (e.g., example code) is a best fit for one's code is still non-existent. This makes both the evaluation and the integration of such example code heavyweight, tedious, and error-prone. The consequent effect of this problem is a significant reduction of productivity.

%%Both Facebook and Twitter are popular services with different purpose and functionality, and yet they share a common feature: text-based status updates. This suggests that there is an exploitable correspondence between the ``status updates'' source code of the two services' APIs. Due to these services' popularity in the open source world\footnote{Search for Twitter or Facebook at \url{www.github.com}.}, it is common for one to rely on the proliferation of open source software and the availability of code search tools to find large sets of relevant examples~\cite{Reiss2009}. These are examples that could potentially help changed the sentiment analysis tool to use the Facebook API. Even if one were to overlook these dependencies, the absence of tool support for \emph{anticipating} the usefulness of retrieved examples makes retargeting\footnote{Retargeting is the process of altering source code to fit an alternate context.} tasks heavyweight, tedious, and error-prone. %All these factors combined imply that code search all by itself doesn't solve the whole problem.%%In the context of modifying the bullying detection program, the absence of such tool support could lead to the developer going beyond the time allocated for the task or not finishing the task at all. This is augmented, in part, by the %%developer constantly switching \emph{back and forth} between results evaluation and further searches. 
% 
% Obviously, code search all by itself doesn't solve the whole problem. In fact, code-only searching misses out on certain human abilities that are important in search-driven development, such as the ability to quickly identify better results among a myriad of retrieved examples, to demarcate feasible regions of code, and to transform results into code that resembles what existed only in the human mind. Do note there are systems, such as~\cite{Bajracharya:2010um, Gysin:2010kt, Hartmann:2010hx, McMillan:2012dj, Sawadsky:2011eh, Wightman:2012gc} that are starting to address these issues; each with unique strengths and weaknesses. However, tool support for predetermining the usefulness of any search result based on the above abilities is inchoate, leaving developers to perform the retargeting\footnote{Retargeting is the process of altering a source code to fit an alternate context} the old fashioned way. The consequent effect of these limitations is a surprisingly significant reduction of productivity~\cite{Cypher:2010ub, Gysin:2010kt}.

To address the above limitation and thus alleviate its consequent problem, I propose a new approach in search-oriented architecture, called \emph{Snippet Retargeting Approach} or simply \uppercase{SnipR}. \uppercase{SnipR} complements code search with code retargeting\footnote{The process of changing code---designed for one context---to make it more suited to a new context.} capabilities. The intent of these capabilities is to expedite the process of determining if a source code is a best fit; i.e., suitable. It fulfills this by engaging developers in a virtuous loop where they check their retargeting ideas as they think of them, and select only the snippets they can justify as suitable. That is, the found snippet is retargetable---no syntax problems---and the edit distance between this code and the way the code should be in the project under development is minimum. Consequently, it is hypothesized that when developers include retargeting in the code search practice, they can confidently `under-tinker'\todo{Add Cite} compared to the level of tinkering they might expect with unjustifiable source code.   

The code retargeting capabilities are embedded within the \emph{query processing} step of a code search engine in order to automatically modify retrieved source code. Each query, issued by a developer, is interpreted by the query engine not only as a request for a particular result set, but also as a command to retarget relevant bodies of code in that set; e.g., to modify a retrieved example to use an alternative API. With this in mind, the suitability of example code can now be predetermined by applying code mappings to this example code and to later and similar examples. 

A code mapping is a code transformation learned from code examples (i.e., search results) and encapsulated in a representation that could be accessed algorithmically. They specify how two or more code examples correspond, and when applied to a base example, it produces a variation containing the changes specified by the mapping. This type of code retargeting is performed in place, without requiring developers to leave the search interface. With regard to the sentiment analysis tool example, \uppercase{SnipR} allows an iterative approach for changing the tool's code from using the Twitter API to using the Facebook API. One would issue a query; inspect the result set; demarcate code blocks to be transitioned; retarget examples; and evaluate the modified examples (See Figure~\ref{fig:retargeting}). At this point, one would rely on the suitability of these candidates to identify the next course of action.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{images/searchprocess}
    \caption{Search Process before and with \uppercase{SnipR}.}
    \label{fig:retargeting}
\end{figure}
\pagebreak

Figure~\ref{fig:retargeting} illustrates the search process before and with \uppercase{SnipR}. A pre--\uppercase{SnipR} scenario requires effort from the developer to find and select the most promising examples (i.e., screening), and to evaluate each one of them before eventually consuming them (e.g., done with integration) after many code modifications in the IDE. If the resulting code is not the desired code, then the search process is restarted by the developer. In the \uppercase{SnipR} scenario, the developer engages in a virtuous loop where he/she finds and selects only the promising examples that can be retargeted. This minimizes the number of iterations in the search process, since the evaluation step is only dealing with best choices---choices that would be easier to consume at the IDE.

In retrospect, if the time required to determine the most suitable results is minimized by retargeting, then the effort of integrating these search results is also minimized. If retargeting is unsuccessful, then the developer will continue searching for more examples and retarget as needed. Overall, \uppercase{SnipR} will allow code queries and retargeting requests\footnote{The everyday search box would be enhanced with command line power; e.g., code manipulation commands.} to be intermixed---or used separately---by the developer to explore potential code changes on the retrieved results (See \uppercase{SnipR} scenario in Figure~\ref{fig:retargeting}). This offers two important advantages. If the developer is retargeting the source in advance, then the evaluation results of retargeted examples are available immediately, which saves valuable human time searching for an appropriate example code. If the developer is choosing what example code to retarget, then the evaluation results can inform the decision, pointing the developer to the best choice. This is an attractive proposition and very different to the directions taken by previous work. It is attractive because one can figure out as early as possible if an example code is appropriate or not. It is different because one can do this without requiring to leave the search interface.
% This proposed approach suggests an environment where human and search engine help each other out and accept the challenge of retargeting code on the spot.  

This work proposes the following solutions to the aforementioned problem:

\begin{itemize}
\item A command line language for retargeting source code. 
\item Algorithms for learning and using code mappings from example code. 
\item A set of retargeting operators well suited for manipulating example code; i.e., applying code mappings.
\item A realization of the \uppercase{SnipR} conceptual architecture in a working system---e.g., Sourcerer\cite{Bajracharya:2006vn}---for code search and retargeting. 
\item An evaluation of the efficiency of the \uppercase{SnipR} approach versus existing approaches for doing code search and retargeting tasks. 
\end{itemize}

These solutions are the expected contributions of this work in search-driven development and thus in software engineering. 

\input{proposal/questions}
\input{proposal/outline}