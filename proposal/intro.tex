\chapter{Introduction}{}
\label{sec:intro}

\lettrine[lraise=0.1, nindent=0em, slope=-.5em]{T} {HE RECENT RISE} of Internet-scale code search engines---e.g., Sourcerer~\cite{Bajracharya:2006vn}, Portfolio~\cite{McMillan:2011wq}, SEAHAWK's Crawley~\cite{Bacchelli:2012dl}, Koders~\footnote{\url{http://www.koders.com}}---has catapulted search-driven development from backwater to ubiquity, and given rise to an active research community focused on this phenomena~\cite{Bajracharya:2009fj, Bajracharya:2010iy, Bajracharya:2011kw}. The increased prevalence of such engines has given search-driven development more diverse sources of information---e.g., from open sourced code to code snippets from StackOverflow~\footnote{\url{http://www.stackoverflow.com}} on programming questions---and a more open platform---the Internet~\cite{GallardoValencia:2009gr, GallardoValencia:2010ij, Ying:2012tr}. This new condition has enabled developers to build applications opportunistically by iteratively finding, combining, and reusing online source code~\cite{Brandt:2008wi, Brandt:2009jb, Ying:2012tr}. However, this opportunistic way of building applications is not easy because searched sources are large, in most cases unsuitable, and quite often unrelated~\cite{GallardoValencia:2009gr}. Consequently, if one wants to establish search-driven development as a best practice, then one has to minimize the time involved in deciding the best search result(s) to reuse.

Previously published work has tried to tackle the above problem from different directions. Two of these directions are the most popular. One direction focuses entirely on enhancing search technology~\cite{Bajracharya:2010um, Gysin:2010kt, Mandelin:2005uj, McMillan:2011cm, McMillan:2012dj}, while the other direction focuses on coupling Web search and community-based knowledge with IDEs~\cite{Bacchelli:2012dl, Brandt:2010tp, Hartmann:2010hx, Hoffmann:2007wo, Wightman:2012gc}. Although these directions focus on addressing the trustability and relevance of search results, none of them adequately address the \emph{suitability} of these results. In other words, developers are given no guidance as to which result may be a best fit for their code in progress, beyond the existing ranking values. Precisely, developers still have to \emph{manually} mine and try all these ranked results before they could possibly realize their usefulness---or uselessness. This limitation is one of the main reasons why search-driven development is so cumbersome, and ultimately can be a drain on one of the most precious resources in software development: time.

An increasingly familiar example of search-driven development arises when modifying a program to support a particular set of functionality. Sometimes, the task is to reuse external third-party libraries, or to support algorithms with specific performance characteristics. Other times, a developer may want to support a feature implemented by code with a conflicting API\footnote{Application Programming Interface (API)}. A good example would be adapting a sentiment analysis tool (that uses the Twitter API) to use the Facebook API. This type of tool permits the classification of opinions in text (e.g., status updates in Twitter) into categories like ``positive'' or ``negative.'' 

The increased prevalence of open source software and code search tools makes it simpler to find large sets of relevant examples~\cite{Reiss:2009fu}. As for the above sentiment analysis tool, one could find around fifty platform-specific Facebook libraries and a few dozens general-purpose Facebook libraries on Github\footnote{\url{http://www.github.com}}, each with unique differences and similarities. Tool support for \emph{anticipating} whether any source code found in those libraries is a best fit for one's code is basically non-existent, making any integration tasks heavyweight, tedious, and error-prone. 

%Both Facebook and Twitter are popular services with different purpose and functionality, and yet they share a common feature: text-based status updates. This suggests that there is an exploitable correspondence between the ``status updates'' source code of the two services' APIs. Due to these services' popularity in the open source world\footnote{Search for Twitter or Facebook at \url{www.github.com}.}, it is common for one to rely on the proliferation of open source software and the availability of code search tools to find large sets of relevant examples~\cite{Reiss2009}. These are examples that could potentially help changed the sentiment analysis tool to use the Facebook API. Even if one were to overlook these dependencies, the absence of tool support for \emph{anticipating} the usefulness of retrieved examples makes retargeting\footnote{Retargeting is the process of altering source code to fit an alternate context.} tasks heavyweight, tedious, and error-prone. %All these factors combined imply that code search all by itself doesn't solve the whole problem.%%In the context of modifying the bullying detection program, the absence of such tool support could lead to the developer going beyond the time allocated for the task or not finishing the task at all. This is augmented, in part, by the %developer constantly switching \emph{back and forth} between results evaluation and further searches. 

Obviously, code search all by itself doesn't solve the whole problem. In fact, code-only searching misses out on certain human abilities that are important in search-driven development, such as the ability to quickly identify better results among a myriad of retrieved examples, to highlight relevant elements (e.g., variable names), to demarcate feasible regions of code, and to transform results into code that resembles what existed only in the human mind. Do note there are systems, such as~\cite{Bajracharya:2010um, Gysin:2010kt, Hartmann:2010hx, McMillan:2012dj, Sawadsky:2011eh, Wightman:2012gc} that are starting to address these issues; each with unique strengths and weaknesses. However, tool support for anticipating the usefulness of any potentially suitable search result based on the above abilities is inchoate, leaving developers to perform the retargeting\footnote{Retargeting is the process of altering a source code to fit an alternate context} the old fashioned way. The consequent effect of these limitations is a surprisingly significant reduction of productivity~\cite{Cypher:2010ub, Gysin:2010kt}.

Given this hit on productivity, I propose a radically new approach in search-oriented architecture, called \emph{Snippet Retargeting Model} or simply \emph{SnipR}. This approach complements code search by supercharging it with code retargeting capabilities. The intent of these capabilities is to expedite the process of determining if a source code is a best fit; i.e., suitable. These capabilities are embedded within \emph{query processing} in order to automatically modify retrieved source code. Each query issued by a developer is interpreted by the query engine not only as a request for a particular result set, but also as a command to retarget relevant bodies of code in that set; e.g., modify a retrieved example---in place---to use an alternative API. With this in mind, the usefulness of retrieved source code can now be quickly realized by applying, within query operators, code mappings to the retrieved source code and to later and similar examples. A code mapping is a semantic-preserving code transformation learned from code examples (i.e., search results) and encapsulated in a representation that could be accessed algorithmically. They specify how two or more code examples correspond, and when applied to a base example, it produces a variation containing the code changes specified by the mapping. This type of code retargeting is performed in place, without requiring to leave the search interface. As for the sentiment analysis tool, \emph{SnipR} would allow an iterative approach for changing the tool's code from using the Twitter API to using the Facebook API. One would inspect the result set; demarcate the code block (s) to be transitioned; infer corresponding mappings; apply these mappings; and evaluate the resulting examples. At this point, one would rely on the suitability of these candidates to identify the next course of action.    

In retrospect, if the time required to determine the most suitable results is minimized by retargeting, then the effort of integrating these search results is also minimized. If retargeting is unsuccessful, then the developer will continue searching for more examples and retarget as needed. Overall, \emph{SnipR} will let users do common \emph{code manipulation} tasks---usually found in development environments---directly from the \emph{search box}\footnote{The everyday search box would be enhanced with command line power; e.g., code manipulation commands.}. This is an attractive proposition and very different to the direction taken by the status quo. This proposed approach suggests an environment where human and search engine help each other out and accept the challenge of retargeting code on the spot. 

\input{proposal/questions}
\input{proposal/outline}