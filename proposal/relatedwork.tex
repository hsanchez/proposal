\chapter{Related Work}{}
\label{sec:related}

\lettrine[lraise=0.1, nindent=0em, slope=-.5em]{S} {NIPR IS RELATED TO} prior work in three areas: tailoring search interfaces for specific tasks; example-centric programming; and systems for making code more suited to a given context.

\fancybreak{\pfbreakdisplay}

\section{Search Interfaces}
\label{sec:searchengines}

Search interfaces can be tailored for specific tasks~\cite{Brandt:2009jb, Morville:2010up, Wightman:2012gc}. Prior work includes systems that support a diverse range of tasks, such as web tasks automation~\cite{Little:2007dh, Teevan:2009fq}, data analysis~\cite{Brandt:2009jb, Medynskiy:2009th}, and programming~\cite{Brandt:2010tp, Mandelin:2005uj, Wightman:2012gc}. Undeniably, programming search interfaces have changed how developers locate code snippets~\cite{Brandt:2010tp, Hoffmann:2007wo, Sahavechaphan:2006tc}. Large sets of code snippets (i.e., example code) are just one search away. This easy access to such an amazing treasure of trove code clearly has value; however, it has also significant limitations as a platform\footnote{e.g., Code search engines may incorporate language semantics, but they mainly index repositories of working code bases, making them less helpful for retargeting tasks.}. So regardless of any ranking values, it is still difficult for developers to determine whether or not a found code is really suitable. The less someone knows about the found code, the poorer judge someone is about if a search result is a best fit for the task in progress. With regard to how current programming search interfaces differ from \uppercase{SnipR}, it is envisioned that \uppercase{SnipR} is not seen as their competitor, but more like a platform: a platform for finding suitable example via code retargeting.
% 
% 
% In recent years many code-centric search engines have appeared. These engines rely on either keywords, unit tests, open source project's metadata, semantic information, or any combination thereof to find large sets of relevant example code. Undeniably, these engines have changed how developers find information. Large sets of example code are just one search away. This easy access to such an amazing treasure of trove code clearly has value; however, it has also significant limitations as a platform. These engines leave the suitability scrutiny---done manually---of returned results to the developers. With regard to how these engines differ from \uppercase{SnipR}, it is envisioned that \uppercase{SnipR} is not seen as a competitor to any code search search engine, but more like a platform: a platform these engines can use for finding suitable example via code retargeting.
% % These engines utilize sophisticated ranking formulas for returning results that correspond with the developers' search, leaving the suitability scrutiny---done manually---of returned results to the developers.

Snippet search interfaces are distinguished by how users can query them; for instance, Sourcerer's interface~\cite{Bajracharya:2006vn, Bajracharya:2010um} uses program structures and semantics, while 
Merobase's interface~\cite{Hummel:eq} uses a combination structured code search and metrics---e.g., cyclomatic and Halstead complexity---to find relevant source code. Portfolio\cite{McMillan:2011cm, McMillan:2011wq} uses a combination of natural language processing (NLP), while Prospector~\cite{Mandelin:2005uj} uses input and output types. Seahawk~\cite{Bacchelli:2012dl} exploits Stackoverflow\footnote{\url{http://www.stackoverflow.com}}'s crowd knowledge to generate queries. Other systems, such as the S$^{6}$ project\cite{Reiss:2009fu}, Code Genie~\cite{LazzariniLemos:2007jh}, and Code Conjurer~\cite{Hummel:eq} use a combination of query expansion via unit tests, and meaningful specifications over source code to find relevant example code.
 
\fancybreak{\pfbreakdisplay}

\section{Finding Suitable Examples}
\label{sec:codesearch}

Many systems have been built to help developers find trustable and relevant example code, including systems that have leveraged crowdsourced input to suggest solutions to developers' code problems. Broadly speaking, \uppercase{SnipR} differs from this prior work by supporting a direct exploration of potential future code changes of found examples. Supporting this direct exploration enables developers to have more confidence sooner that the picked example (s) is the right one; it also avoids some of the ``round-trip'' errors that can arise when developers iteratively edit unsuitable example code.

For example, Brandtâ€™s Blueprint system~\cite{Brandt:2010tp} couples Web search with development environments. Assieme~\cite{Hoffmann:2007wo} combines documentation search results with code snippets of the relevant functions currently in use. Stylos's Mica system~\cite{Stylos:2006gu} integrates search for documentation and example source code. Hartmann's HyperSource system~\cite{Hartmann:2011ii} associates browsing histories with source code edits. Hartmann's HelpMeOut system~\cite{Hartmann:2010hx} aids the debugging of code-related error messages by suggesting solutions that peers have applied in the past. McMillan's Source Code Recommender systems~\cite{McMillan:2012dj} combines mining written code specifications and open sourced code to recommend source code modules relevant to the application under development. Gysin's solution~\cite{Gysin:2010kt} uses a trustability metric based on developers' karma to find trustable code. Lastly, Stolee's semantic search approach~\cite{Stolee:2012wp} uses lightweight specifications and a SMT solver to find suitable code.
% dont trust me just because I am telling u to do it. E.g., dont trust this code is relevant just because there is a score that tells u that.

\fancybreak{\pfbreakdisplay}

\section{Retargeting Source Code}
\label{sec:retargetingcode}

Adapting an example code to a different context is tedious and difficult. Partly because there are many different types of code modifications that might be required to make this code more suited---e.g., variables renamed, and dependencies included. Various attempts have been made to address this problem, many of them include systems for resolving many simple coding errors, systems for suggesting ways for correcting compiler and runtime errors, systems for end-User modification of Web Experiences, or systems for making incremental code changes to available example code in order to make it more suited. Unlike \uppercase{SnipR}, any interaction for finding and/or integrating any example code is done directly in the IDE or in a visual web-based development environment.  

Wightman's SnipMatch~\cite{Wightman:2012gc} introduces a markup that allows snippet authors to specify search patterns and integration instructions. SnipMatch uses this information, in conjunction with the current code context, to semi-automate the integration of example code. Nita's Twinning~\cite{Nita:2010en} allow programmers to specify a set of code-level mappings between alternative APIs. With Twinning, programmers can specify changes that modify a program from using one API to using an alternative API. EUKLAS\footnote{\url{http://www.cs.cmu.edu/~euklas}} highlights simple source code errors and suggest the appropriate corrections. Similar systems include the Eclipse QuickFix and Ernst's Quick Fix Scout\footnote{\url{https://code.google.com/p/quick-fix-scout/}}. These tools allow programmers to quickly resolve many simple errors. Oney's Codelets~\cite{Oney:2012ge} system allows authors of example code to use a form of markup language to indicate those code's regions that can be edited. Lastly, Hartmann's d.mix~\cite{Hartmann:2007wf} allow a direct experimentation of found code on the Web.


